<properties
 pageTitle="Storage configuration issues "
 description="Storage configuration issues "
 service="Microsoft.Databricks"
 resource="Microsoft.Databricks/workspaces"
 authors="AzureData_AzureDatabricks"
 ms.author="AzureData_AzureDatabricks"
 displayOrder=""
 selfHelpType="TSG_Content"
 supportTopicIds=""
 resourceTags=""
 productPesIds=""
 cloudEnvironments="public, fairfax, usnat, ussec"
 articleId="93f3f9f1-4840-4567-ae80-48010deb91d1"
 ownershipId="AzureData_AzureDatabricks"
/>

# Storage configuration issues 

### Symptom

Storage configuration issues - ADLS GEN1 or GEN2. Getting below errors trying to connect to Storage:

`Error: Invalid Config` <br />

`AADToken: HTTP connection failed for getting token from AzureAD. Http response: 401 Unauthorized` <br />

`StatusCode=403- HEAD https://<adls>.dfs.core.windows.net/gen2container1/File1.txt?timeout=90
StatusDescription=This request is not authorized to perform this operation using this permission.` <br />

`java.net.SocketTimeoutException: connect timed out` <br />


### Troubleshooting

1. If secret scope is used, try using the key directly instead of a secret scope.

2. Is it with the key? Try using the key.

3. Check configs:
   - Try with mount dbfs:// and use path dbfs. Follow documentation. Success or fail?
   - Try using in a notebook spark config and path abfss:// . Follow documentation. Success or fail?
   - Try using the spark cluster config. Follow documentation. Success or fail?

4. If all configs fail, is the OAuth correct and token is able to auth?
5. Are both Databricks workspace and ADLS in the same location?
6. Can you telnet to the storage with its IP on port 443?

		%sh telnet <adls>.dfs.core.windows.net 443


### Solution

- Fix the storage access key - Check how the access key was generated. If the access is based on key ensure the key / SAS have full permissions. Customer can create keys with lesser Permisisons from Azure CLI.
- Fix configs 
- Fix connectivity 
- Fix access issue - Check if the user has contributor access and permissions on each object.
- If they are using keyvault, check and fix key vault access.
- If using AD based authentication to storage, enable compulsary AD endpoint on both subnets of Databricks.

### Recommended Documents

* [Accessing ADLS Gen 1](https://docs.microsoft.com/en-us/azure/databricks/data/data-sources/azure/azure-datalake)
* [Accessing ADLS Gen 2](https://docs.microsoft.com/en-us/azure/databricks/data/data-sources/azure/azure-datalake-gen2)

### Next Steps

- If error is server side or server busy 5xx, escalate to SME on Ava and file IcM if needed.
- If error is client side or server busy 4xx, escalate to SME on Ava and file Databricks Salesforce ticket if needed.
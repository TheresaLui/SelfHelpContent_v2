<properties
    pageTitle="Spark-shell configuration"
    description="Spark-shell configuration"
    service="microsoft.hdinsight"
    resource="clusters"
    authors="bharathsreenivas"
    displayOrder="9"
    selfHelpType="resource"
    supportTopicIds="32511212,32511216"
    resourceTags=""
    productPesIds=""
    cloudEnvironments="public"
/>

# Spark application configuration through Ambari

The amount of memory and number of cores used by Spark-Shell can be configured to optimize Spark performance

## **Recommended documents**
[Spark-Shell configuration](https://hdinsight.github.io/spark/spark-shell-configuration.html)<br>

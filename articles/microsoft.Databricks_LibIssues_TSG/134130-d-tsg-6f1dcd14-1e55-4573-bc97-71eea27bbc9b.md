<properties
 pageTitle="ClassNotFoundException "
 description="ClassNotFoundException "
 service="Microsoft.Databricks"
 resource="Microsoft.Databricks/workspaces"
 authors="AzureData_AzureDatabricks"
 ms.author="AzureData_AzureDatabricks"
 displayOrder=""
 selfHelpType="TSG_Content"
 supportTopicIds=""
 resourceTags=""
 productPesIds=""
 cloudEnvironments="public, fairfax, usnat, ussec"
 articleId="6f1dcd14-1e55-4573-bc97-71eea27bbc9b"
 ownershipId="AzureData_AzureDatabricks"
/>

# ClassNotFoundException 

### Symptom

JAR library throws ClassNotFoundException even though class is present in attached library.

When we install libraries via the library UI, we are dynamically adding jars/eggs to spark's classloader, while when we install libraries via an init script, we are adding jars/eggs to the root classloader.

This problem occurs when the library itself is reading from the wrong classloader.

### Solution

[Installing a library via Init Scripts](https://docs.microsoft.com/en-us/azure/databricks/clusters/init-scripts) can be used to place the library on the root classloader. Note that this means that you would no longer be using the Databricks Libraries UI, REST API, etc.

### Next Steps

If issue persists, involve SME on Ava and file a Databricks SF ticket if needed.

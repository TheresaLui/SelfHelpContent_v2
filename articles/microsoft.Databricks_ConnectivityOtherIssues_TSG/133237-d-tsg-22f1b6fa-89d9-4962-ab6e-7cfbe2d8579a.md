<properties
 pageTitle="MAX_NOTEBOOK_SIZE_EXCEEDED"
 description="MAX_NOTEBOOK_SIZE_EXCEEDED"
 service="Microsoft.Databricks"
 resource="Microsoft.Databricks/workspaces"
 authors="AzureData_AzureDatabricks"
 ms.author="AzureData_AzureDatabricks"
 displayOrder=""
 selfHelpType="TSG_Content"
 supportTopicIds=""
 resourceTags=""
 productPesIds=""
 cloudEnvironments="public, fairfax, usnat, ussec"
 articleId="22f1b6fa-89d9-4962-ab6e-7cfbe2d8579a"
 ownershipId="AzureData_AzureDatabricks"
/>

# MAX_NOTEBOOK_SIZE_EXCEEDED

### Symptom

Notebook export API call fail with the error `MAX_NOTEBOOK_SIZE_EXCEEDED`.

### Suggested Solution

Export REST API directly has 10MB limit. If it goes beyond that limit, it would return MAX_NOTEBOOK_SIZE_EXCEEDED. Below are the possible options to resolve it:

* **Approach 1** - Limit the size of the notebook/directories to less than 10 MB, perform export from the source workspace, and then import the archive file in the destination workspace.

* **Approach 2** - If the notebook/directories are slightly larger than 10 MB, then use the databricks CLI to perform the export and import. Example:

  	`databricks workspace export_dir /Users/user/test /tmp/`
		
  	`databricks workspace import_dir /tmp/ /Users/user/test`


* **Approach 3** - Integrate the Notebooks with Github. Changes can be committed to Github through the notebook. Sync the notebooks with Github and on the destination shard. The changes made in the source shard can be viewed under Revision History in the Destination shard. The revision history will have each commit made to the remote Github repository.


### Recommended Documents

[Databricks Workspace CLI](https://docs.microsoft.com/en-us/azure/databricks/dev-tools/cli/workspace-cli)
[Github Version Control](https://docs.microsoft.com/en-us/azure/databricks/notebooks/github-version-control)
<properties
  pagetitle="Mapping DataFlow - Performance Issue Common Solutions&#xD;"
  service=""
  resource=""
  ms.author="rakatuko"
  selfhelptype="Generic"
  supporttopicids="32633537"
  resourcetags=""
  productpesids="15613"
  cloudenvironments="fairfax,public,usnat,ussec"
  disableclouds="blackforest,mooncake"
  articleid="a53cdff2-4487-47bf-a211-bfcaa4f25013"
  ownershipid="AzureData_DataFactory" />
# Mapping DataFlow - Performance Issue Common Solutions

Most users can resolve performance issues concerning dataflow, including optimizing dataflow, by using the following information.

## **Recommended Steps**

Following are typical scenarios involving dataflow, with specific guidance.

**Optimizing sources**

See this [general guide to optimizing sources](https://docs.microsoft.com/azure/data-factory/concepts-data-flow-performance#optimizing-sources). Keep the following in mind:
- File-based sources are already highly optimized for reading. Any partitioning that uses [optimized tabs](https://docs.microsoft.com/azure/data-factory/concepts-data-flow-performance#file-based-sources) is going to slow down the performance.
- For file-based sources, if you are using a wildcard path, scope it to the minimum level, because file discovery is a time-consuming process. For instance, if you are looking for all files in a particular directory, use `myDirectory/myFiles*.csv` rather than `**/myfiles*.csv`.
- SQL source should use [source-based partitioning](https://docs.microsoft.com/azure/data-factory/concepts-data-flow-performance#azure-sql-database-sources). This will enable dataflow to read from SQL using multiple partitions. Make sure not to overwhelm SQL Server by adding too many partitions.
- For sources like [Azure Synapse Analytics](https://docs.microsoft.com/azure/data-factory/concepts-data-flow-performance#azure-synapse-analytics-sources), use staging to land data first in Azure storage. This will boost the overall performance. By default, this option is on.

**Optimizing sinks**

See this [general guide to optimizing sinks](https://docs.microsoft.com/azure/data-factory/concepts-data-flow-performance#optimizing-sinks). Keep the following in mind:
- Use current partitioning for sinks, unless there is a requirement to write data differently.
- Outputting to a single file and **As Data in column** takes more time. We recommend that you use partitioning in your downstream applications (such as Dataflow, Copy, and Spark).

**Optimizing transformations**

See this [general guide for transformation optimization](https://docs.microsoft.com/azure/data-factory/concepts-data-flow-performance#optimizing-transformations). <br/>

- Use the default partition for the transformations, until you see that data is [skewed in a partition](https://docs.microsoft.com/azure/data-factory/concepts-data-flow-performance#repartitioning-skewed-data). Even in that case, repartitioning might be more costly than just finishing the dataflow with the current partitioning scheme.
- Consider [broadcasting](https://docs.microsoft.com/azure/data-factory/concepts-data-flow-performance#broadcasting) for the small streams in Join, Lookup, and Stream transformations. 
- Avoid cross-joining unless required. See [more information](https://docs.microsoft.com/azure/data-factory/concepts-data-flow-performance#cross-joins).
- Few transformations create around 200 partitions, such as join, windows, aggregate, exists, lookup to optimize these operations.

**Running Dataflow in pipelines**

- Each Dataflow runs in isolation on a cluster, running multiple Dataflows in [parallel](https://docs.microsoft.com/azure/data-factory/concepts-data-flow-performance#executing-data-flows-in-parallel), create multiple clusters behind the scene.<br/>
- Run Dataflow [sequentially](https://docs.microsoft.com/azure/data-factory/concepts-data-flow-performance#execute-data-flows-sequentially) to take benefit of [Time to live](https://docs.microsoft.com/azure/data-factory/concepts-data-flow-performance#time-to-live) on the cluster, this will save time to spin up the cluster.

**FAQs**
**Why is cluster acquisition time high? <br>
Dataflow uses Spark behind the scene and spi**n clusters. If you want to reduce the cluster startup time, you can use the [Time to live](https://docs.microsoft.com/azure/data-factory/concepts-data-flow-performance#time-to-live) feature.

**I am using partitions, but Dataflow is still slow.**<br>
Generally, avoid partitioning other than where it is required, as mentioned above regarding source-based scenarios.

**Writing to a single file or "Use column data as filename" features take too much time.**<br>
Both of these features require execution in very limited threading. When data is written to a single file, it must be written using a single thread, so these features take time to complete.

**For very few records, Dataflow takes 5-7 minutes.**<br>
Dataflow runs on a Spark cluster. Check the compute acquisition time to determine the actual processing time. 

**Recommended Documents** 

- [DataFlow Monitoring](https://docs.microsoft.com/azure/data-factory/concepts-data-flow-monitoring)
- [Total Sink Processing Time vs. Transformation Processing Time](https://docs.microsoft.com/azure/data-factory/concepts-data-flow-monitoring#total-sink-processing-time-vs-transformation-processing-time)
- [Mapping dataflows in Azure Data Factory Overview](https://docs.microsoft.com/azure/data-factory/concepts-data-flow-overview)
- [Mapping dataflow Datasets](https://docs.microsoft.com/azure/data-factory/concepts-data-flow-datasets)
- [Mapping dataflow Debug mode](https://docs.microsoft.com/azure/data-factory/concepts-data-flow-debug-mode)
- [Execute dataflow activity in Azure Data Factory](https://docs.microsoft.com/azure/data-factory/control-flow-execute-data-flow-activity)
- [Azure Data Factory FAQ](https://docs.microsoft.com/azure/data-factory/frequently-asked-questions)
- [Feature Request](https://feedback.azure.com/forums/270578-azure-data-factory)
